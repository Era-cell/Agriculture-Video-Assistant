{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d339139a-913c-4015-8a7f-76a4c1bbf1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abhinav.i.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing all necessary libraries\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "img_width, img_height = 224, 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1be77e4-d7a1-4e5a-b450-1f2e183f8cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "directory=\"C:/Users/abhinav.i.s/Downloads/apple\"\n",
    "count=0\n",
    "for name in os.listdir(directory):\n",
    "    count+=len([f for f in os.listdir(os.path.join(directory,name)) if os.path.isfile(os.path.join(os.path.join(directory,name), f))])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45da7e7a-0f4b-4f81-afdd-88e336bac78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"C:/Users/abhinav.i.s/Downloads/apple\"\n",
    "validation_data_dir = \"C:/Users/abhinav.i.s/Downloads/apple\"\n",
    "nb_train_samples =count\n",
    "nb_validation_samples = count\n",
    "epochs = 20\n",
    "batch_size = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "931432e6-9c39-455a-8c31-a33a0b73d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "\tinput_shape = (3, img_width, img_height)\n",
    "else:\n",
    "\tinput_shape = (img_width, img_height, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab599b0-65b8-459f-940a-3b263a17f2bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m()\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m), input_shape\u001b[38;5;241m=\u001b[39minput_shape))\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (4, 4), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4d6efe1-fc05-479b-8c7a-8f1fd1d5bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee949d16-b9ff-4668-82b8-13cdd4590470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 4 classes.\n",
      "Found 20 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhinav.i.s\\AppData\\Local\\Temp\\ipykernel_3152\\1601187790.py:22: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 4s 695ms/step - loss: 2.3965 - accuracy: 0.3500 - val_loss: 1.4146 - val_accuracy: 0.2500\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 2s 491ms/step - loss: 1.4313 - accuracy: 0.3000 - val_loss: 1.3800 - val_accuracy: 0.2500\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 2s 514ms/step - loss: 1.4265 - accuracy: 0.3500 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 2s 479ms/step - loss: 1.4523 - accuracy: 0.3000 - val_loss: 1.2962 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 2s 499ms/step - loss: 1.3246 - accuracy: 0.3000 - val_loss: 1.1586 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 2s 466ms/step - loss: 1.1110 - accuracy: 0.5000 - val_loss: 0.8593 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 2s 473ms/step - loss: 1.6619 - accuracy: 0.4000 - val_loss: 1.1513 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 2s 516ms/step - loss: 1.1547 - accuracy: 0.5000 - val_loss: 0.9635 - val_accuracy: 0.6500\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 2s 481ms/step - loss: 1.1494 - accuracy: 0.5500 - val_loss: 0.7444 - val_accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 2s 476ms/step - loss: 0.9010 - accuracy: 0.6000 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 2s 483ms/step - loss: 0.6730 - accuracy: 0.6500 - val_loss: 0.3202 - val_accuracy: 0.9500\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 2s 490ms/step - loss: 0.9854 - accuracy: 0.6500 - val_loss: 0.7366 - val_accuracy: 0.7000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 2s 472ms/step - loss: 0.7988 - accuracy: 0.7000 - val_loss: 0.3755 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 2s 489ms/step - loss: 0.4685 - accuracy: 0.8000 - val_loss: 0.3148 - val_accuracy: 0.9000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 2s 473ms/step - loss: 0.3583 - accuracy: 0.9000 - val_loss: 0.3399 - val_accuracy: 0.9000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 2s 514ms/step - loss: 0.9849 - accuracy: 0.5500 - val_loss: 0.2376 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 2s 520ms/step - loss: 0.4089 - accuracy: 0.8000 - val_loss: 0.1299 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 2s 511ms/step - loss: 0.3244 - accuracy: 0.8500 - val_loss: 0.1612 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 2s 550ms/step - loss: 0.5112 - accuracy: 0.8500 - val_loss: 0.1111 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 2s 493ms/step - loss: 1.7336 - accuracy: 0.7000 - val_loss: 0.2256 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x259844e0090>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a28deb-9f6c-46e1-9082-8cd938263ba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_saved4.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('model_saved4.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec90480-3774-4a71-a8e6-f2b7d8addd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abhinav.i.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\abhinav.i.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\abhinav.i.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "class is potassium\n",
      "[[0.8510206  0.15368336 0.23885469]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model_saved3.h5')\n",
    "\n",
    "image = load_img(\"C:/Users/abhinav.i.s/Downloads/archive (3)/rice_plant_lacks_nutrients/Nitrogen(N)/untitled-94.JPG\", target_size=(224, 224))\n",
    "img = np.array(image)\n",
    "img = img / 255.0\n",
    "img = img.reshape(1,224,224,3)\n",
    "label = model.predict(img)\n",
    "maxIndex=-1\n",
    "a=label[0]\n",
    "i=0\n",
    "import numpy as np\n",
    "i=np.argmax(a)\n",
    "if i==0:\n",
    "    print(\"class is potassium\")\n",
    "elif i==1:\n",
    "    print(\"class is phosphorous\")\n",
    "else:\n",
    "    print(\"class is nitrogen\")\n",
    "#print(\"Predicted Class (0 - Cars , 1- Planes): \", label[0][0])\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5395a37b-fe95-4d2f-b37e-65a145d87600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abhinav.i.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\abhinav.i.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "doc=\"\"\n",
    "model = load_model('model_saved4.h5')\n",
    "def predict_image(img):\n",
    "    \n",
    "    image=load_img(img,target_size=(224,224))\n",
    "    img1 = np.array(image)\n",
    "    img1 = img1 / 255.0\n",
    "    img1 = img1.reshape(1,224,224,3)\n",
    "    label = model.predict(img1)\n",
    "    a=label[0]\n",
    "    i=0\n",
    "    i=np.argmax(a)\n",
    "    if i==0:\n",
    "     return \"1\"\n",
    "    elif i==1:\n",
    "     return \"2\"\n",
    "    elif i==2:\n",
    "     return \"3\"\n",
    "    elif i==3:\n",
    "     return \"4\"\n",
    "    elif i==4:\n",
    "     return \"5\"\n",
    "    elif i==5:\n",
    "     return \"6\"\n",
    "    else :\n",
    "     return \"7\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b068f5b6-4eaf-4f5c-bd13-74960839b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings,OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import AzureOpenAI\n",
    "import constants\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\"\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "def botmessage(query,cl):\n",
    " doc=\"\"\n",
    " if cl==\"3\":\n",
    "     doc=\"C:/Users/abhinav.i.s/Downloads/docs/Phosporous deficiency in rice.pdf\"\n",
    " elif cl==\"4\":\n",
    "     doc=\"C:/Users/abhinav.i.s/Downloads/docs/Potasium deficiency in rice.pdf\"\n",
    " #elif cl==\"3\":\n",
    "     doc=\"C:/Users/abhinav.i.s/Downloads/docs/Nitrogen deficiency in rice.pdf\"\n",
    " elif cl==\"2\":\n",
    "     doc=\"C:/Users/abhinav.i.s/Downloads/docs/Apple_Black_rot.pdf\"\n",
    " #elif cl==\"5\":\n",
    "     doc=\"C:/Users/abhinav.i.s/Downloads/docs/Apple_Cedar_rust.pdf\"\n",
    " #elif cl==\"6\":\n",
    "     doc=\"C:/Users/abhinav.i.s/Downloads/hm docs/Prevention Of Sexual Harassment Policy.pdf\"\n",
    " elif cl==\"1\":\n",
    "     doc=\"C:/Users/abhinav.i.s/Downloads/docs/apple_scab.pdf\"\n",
    " loader = PyPDFLoader(doc)\n",
    " documents=loader.load()\n",
    " text_splitter=CharacterTextSplitter(chunk_size=3000,chunk_overlap=0)\n",
    " texts=text_splitter.split_documents(documents)\n",
    " embeddings=OpenAIEmbeddings()\n",
    " search=Chroma.from_documents(texts,embeddings)\n",
    " chain=RetrievalQA.from_chain_type(llm=ChatOpenAI(),chain_type='stuff',retriever=search.as_retriever())\n",
    " return chain.run(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e178adae-7c51-498a-8cab-8a563b3ade56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "with gr.Blocks() as demo:\n",
    " image = gr.Image(type= 'filepath',height=300,width=300)\n",
    " msg = gr.Textbox(visible=False)\n",
    " #submit_button1 = gr.Button(\"Submit\")\n",
    " #submit_button1.click(fn=predict_image,inputs=image,outputs=image)\n",
    " gr.Interface(fn=predict_image,inputs=image,outputs=msg)\n",
    " chatbot = gr.Chatbot()\n",
    " \n",
    " \n",
    " msg2=gr.Textbox()\n",
    " #submit_button2 = gr.Button(\"Submit\")\n",
    " clear = gr.ClearButton([msg2, chatbot])\n",
    " def respond(message,cl, chat_history):\n",
    "        bot_message = botmessage(query=message,cl=cl)\n",
    "        chat_history.append((message, bot_message))\n",
    "        time.sleep(2)\n",
    "        return \"\", chat_history\n",
    " \n",
    " msg2.submit(respond, [msg2,msg, chatbot], [msg2, chatbot])\n",
    " \n",
    " #image.submit(respond)\n",
    "if __name__==\"__main__\":\n",
    "  demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d39805b5-aae2-4451-ae6e-d0d9e7cbdb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_image(\"C:/Users/abhinav.i.s/Downloads/apple/Apple___Black_rot/ff4e792b-14c5-41db-af9e-0676abf8d20a___JR_FrgE.S 3088_new30degFlipLR.JPG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a249ef2-9eb3-4ac8-9eed-c546180690a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7511608-136e-41b5-a8d2-9da7822ee3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc6fa2-bdd6-460c-b84b-4b5ead597372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
